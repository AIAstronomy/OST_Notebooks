{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Open SAR Toolkit - Tutorial 1, version 1.1,  November 2019. Andreas Vollrath, ESA/ESRIN phi-lab</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](auxiliary/header_image.PNG)\n",
    "\n",
    "--------\n",
    "\n",
    "# OST Tutorial I \n",
    "## Pre-processing your first Sentinel-1 image with OST\n",
    "\n",
    "--------\n",
    "\n",
    "**Short description**\n",
    "\n",
    "This notebook introduces you to the *Sentinel_1Scene* class of the Open SAR Toolkit and demonstrates how it can be used to download, extract metadata and pre-process a single Sentinel-1 scene.\n",
    "\n",
    "--------\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- a PC/Mac with at least 16GB of RAM\n",
    "- about 4 GB of free disk space\n",
    "- a NASA Earthdata account with signed EULA for use of https://search.asf.alaska.edu (just register directly there)\n",
    "--------\n",
    "\n",
    "**NOTE:** all cells that have an * after its number can be executed without changing any code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\* - Import the OST *Sentinel1_Scene* class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these imports we need to handle the folders, independent of the OS\n",
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# this is the s1Scene class, that basically handles all the workflow from beginning to the end\n",
    "from ost import Sentinel1_Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2* - Create a folder for our outputs\n",
    "\n",
    "By executing this cell, a new folder will be created and the path will be written to the *processing_dir* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get home folder\n",
    "home = str(Path.home())\n",
    "\n",
    "# create a processing directory\n",
    "output_dir = join(home, 'OpenSarToolkit', 'Tutorial_1')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3* - Choose scene ID and display some metadata\n",
    "\n",
    "In order to initialize an instance of the *Sentinel1_Scene* class, all we need is a valid scene id of a Sentinel-1 product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a S1Scene class instance based on the scene identifier of the first ever Dual-Pol Sentinel-1 IW product\n",
    "#scene_id = 'S1A_IW_GRDH_1SDV_20141003T040550_20141003T040619_002660_002F64_EC04' # actually only available from ASF's data archive\n",
    "scene_id = 'S1A_IW_GRDH_1SDV_20191116T170638_20191116T170703_029939_036AAB_070F'\n",
    "# create an S1Scene instance\n",
    "s1 = Sentinel1_Scene(scene_id)\n",
    "\n",
    "# print summarising infos about the scene\n",
    "s1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4* Download scene\n",
    "\n",
    "The first step is to download the selected scene. In our case we chose the first regular Sentinel-1 IW product acquired in the dual-polarisation VV/VH acquired the 3rd of October 2014. \n",
    "OST provides download from 3 different mirrors, ESA's scihub, CNES PEPS and Alaska Satellite Facility (NASA Earthdata). Since ESA's official scihub became a rolling archive, and so is PEPS, best is to download from the fantastic **Alaska Satellite Facility** mirror (selection 2), which holds the full Sentinel-1 archive online. \n",
    "\n",
    "**Note I:** You can interrupt the download and restart it. The download will continue from where it stopped.\n",
    "\n",
    "**Note II:** At the end the downloaded file will be checked. This assures that the download went fine and we can use it for processing. In addiiton, OST will also magically remember that this file has been successfully downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.download(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5* - Create an ARD product\n",
    "\n",
    "Analysis Ready Data is interpreted differently by different persons. \n",
    "\n",
    "The default ARD type is *'OST Standard'*. For GRD products you can select other pre-defined ARD types, or it allows customising single ARD parameters.\n",
    "\n",
    "See in the cell below the different definitions possible, and also note how the resolution and the resampling of the image during terrain correction is changed at the bottom. In this way, all parameters can be customised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Our ARD parameters dictionary contains 3 keys.')\n",
    "pprint(s1.ard_parameters.keys())\n",
    "print('')\n",
    "print(' Dictionary of our standard OST ARD parameters for the scene processing:')\n",
    "pprint(s1.ard_parameters['single ARD'])\n",
    "print('')\n",
    "\n",
    "\n",
    "# we change ARD type\n",
    "# possible coices are:\n",
    "# 'OST Standard', 'OST Flat', 'CEOS', 'Earth Engine'\n",
    "s1.get_ard_parameters('Earth Engine')\n",
    "print(' Dictionary of Earth Engine ARD parameters for the scene processing:')\n",
    "pprint(s1.ard_parameters['single ARD'])\n",
    "print('')\n",
    "\n",
    "# we cusomize the resolution and image resampling\n",
    "s1.ard_parameters['single ARD']['resolution'] = 50\n",
    "s1.ard_parameters['single ARD']['dem']['image resampling'] = 'BILINEAR_INTERPOLATION'\n",
    "pprint(s1.ard_parameters['single ARD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our *Sentinel1_Scene* class comes with the build-in method *create_ard* to produce a standardised ARD product based on the ARD dictionary above. \n",
    "\n",
    "To run the command we just have to provide: \n",
    "- the path to the downloaded file. We can use the *get_path* method in conjunction with the download directory provided\n",
    "- a directory where the outputfiles will be written to\n",
    "- a filename prefix (the output format will be the standard SNAP Dimap format, consisting of the dim-file and the data directory)\n",
    "- and a directory for storing temporary files (can not be the same as the output folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.create_ard(infile = s1.get_path(output_dir),\n",
    "              out_dir = output_dir,   \n",
    "              out_prefix = s1.start_date,   \n",
    "              temp_dir = '/tmp') # needs to be different from our output dir\n",
    "\n",
    "print(' The path to our newly created ARD product can be obtained the following way:')\n",
    "s1.ard_dimap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6* - Create a RGB color composite\n",
    "\n",
    "Sentinel-1 scenes usually consist of two polarisation bands. In order to create a 3 channel RGB composite a ratio between the Co- (VV or HH) and the Cross-polarised (VH or HV) band is added. The *create_rgb* method takes the *ard_dimap* file and converts it to a 3-channel GeoTiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.create_rgb(outfile = join(output_dir, '{}.tif'.format(s1.start_date)))\n",
    "\n",
    "print(' The path to our newly created RGB product can be obtained the follwing way:')\n",
    "s1.ard_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7* - Visualise the RGB composite\n",
    "\n",
    "We can plot the newly created RGB image with the *visualise_rgb* method. A *shrink_factor* is added, which reduces resolution in favour of memory requirements for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------\n",
    "# for plotting purposes we use this iPython magic\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (23, 23)\n",
    "#---------------------------------------------------\n",
    "s1.visualise_rgb(shrink_factor=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8* - Create thumbnail image\n",
    "\n",
    "For some it might be interesting to create a small thumbnail image in Jpeg format. The *create_rgb_thumbnail* method allows for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a filename for our thumbnail image\n",
    "path_to_thumbnail = join(output_dir, '{}.TN.jpg'.format(s1.start_date))\n",
    "# create the thumbnail image\n",
    "s1.create_rgb_thumbnail(outfile = path_to_thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "img = imageio.imread(path_to_thumbnail)\n",
    "!ls -sh {path_to_thumbnail}\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
