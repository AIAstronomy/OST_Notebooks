{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Open SAR Toolkit - Tutorial 4a, version 1.1, Nobember 2019. Andreas Vollrath, ESA/ESRIN phi-lab</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](auxiliary/header_image.PNG)\n",
    "\n",
    "--------\n",
    "\n",
    "# OST Tutorial IV - A\n",
    "## How to do a batch processing of Sentinel-1 GRD data subset\n",
    "\n",
    "--------\n",
    "\n",
    "**Short description**\n",
    "\n",
    "This notebook shows f OST for the batch processing of GRD data using the *Sentinel1_GRDBatch* class. This is a subclass of the *Sentinel1* class, and thus inherits all the functionalities of the *Generic* and the *Sentinel1* classes presented in Tutorial II. In addition, functions for the generation of calibrated backscatter products are provided. Within the example a subset area will be produced, thus avoiding the overload of processing the full images.\n",
    "\n",
    "--------\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- a PC/Mac with at least 16GB of RAM\n",
    "- about 15GB of free disk space\n",
    "- a Copernicus Open Data Hub user account, valid for at least 7 days (https://scihub.copernicus.eu)\n",
    "--------\n",
    "\n",
    "**NOTE:** all cells that have an * after its number can be executed without changing any code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1* - Import of Libraries\n",
    "\n",
    "In this step we import some standard python libraries for OS independent path handling as well as the *Sentinel1_GRDBatch* class thta handles the full workflow from search, download and processing of multiple GRD scenes. In addition, the OST helper module *vector* is loaded to create an AOI based on Point coordinates, and the *raster* module for creating a time-series animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from ost import Sentinel1_GRDBatch\n",
    "from ost.helpers import vector, raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2* - Set up the project \n",
    "\n",
    "Here you going to initialize the *Sentinel1_GRDBatch* class by determining the project folder, the AOI and the start and end date. Since you should be already familiar with the *search* and *refine* functions, we execute them within the same cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a project directory\n",
    "home = str(Path.home())\n",
    "# create a processing directory\n",
    "project_dir = join(home, 'OpenSarToolkit', 'Tutorial_4a')\n",
    "\n",
    "# define aoi with a 2 point coordinates and create a buffer\n",
    "lat, lon = '47.25', '14'\n",
    "aoi = vector.latlon_to_wkt(lat, lon, buffer_meter=10000, envelope=True)\n",
    "\n",
    "#define the start and end date\n",
    "start = '2019-05-01'\n",
    "end = '2019-05-31'\n",
    "\n",
    "# initialize the class to s1_grd instance\n",
    "s1_grd = Sentinel1_GRDBatch(\n",
    "    project_dir=project_dir,\n",
    "    aoi = aoi,\n",
    "    start = start,\n",
    "    end = end\n",
    ")\n",
    "\n",
    "# trigger the search\n",
    "s1_grd.search()\n",
    "\n",
    "# optional: once you did the search the first time, you can load \n",
    "# the full inventory uncommenting the follwoing 2 lines\n",
    "# and commenting the search command\n",
    "#s1_grd.inventory_file = join(s1_grd.inventory_dir, 'full.inventory.shp')\n",
    "#s1_grd.read_inventory()\n",
    "\n",
    "# do the refinement\n",
    "s1_grd.refine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3* - Plot refined data inventory\n",
    "\n",
    "Here you will visualize the resultant dataframes from the refined search inventory based on the product key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------\n",
    "# for plotting purposes we use this iPython magic\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (19, 19)\n",
    "#---------------------------------------------------\n",
    "\n",
    "# search command\n",
    "key = 'DESCENDING_VVVH'\n",
    "# we plot the full Inventory on a map\n",
    "s1_grd.plot_inventory(s1_grd.refined_inventory_dict[key], transparency=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4* - Download of GRD scenes\n",
    "\n",
    "As already shown in Tutorial II, you will download the scenes based on the refined inventory dataframe for the respective produckt key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_grd.download(s1_grd.refined_inventory_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5* - Set ARD parameters\n",
    "\n",
    "Similar to the *Sentinel1-Scene* class (Tutorial I and III), the *Sentinel1-GRDBatch* class handles the defintion of ARD types in a hierarchical dictionary structure. You can use the same types and steps to customize as for the *Sentinel1-Scene* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single scene ARD parameters\n",
    "s1_grd.ard_parameters['single ARD']['resolution'] = 50\n",
    "s1_grd.ard_parameters['single ARD']['product type'] = 'GTCgamma'\n",
    "s1_grd.ard_parameters['single ARD']['create ls mask'] = False\n",
    "\n",
    "# time-series ARD\n",
    "s1_grd.ard_parameters['time-series ARD']['remove mt speckle'] = False\n",
    "\n",
    "# in case we want to use an external dem\n",
    "#s1_grd.set_external_dem('path/to/externaldem')\n",
    "\n",
    "pprint(s1_grd.ard_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6* - Run the batch routine\n",
    "\n",
    "To process all the data, including time-series and timescans is as easy as one command. All the complexity is handled behind, and you just have to wait, since processing can take quite a while.\n",
    "\n",
    "**Note** that as a last argument we submit the AOI (given as WKT) for subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_grd.grds_to_ard(\n",
    "    inventory_df=s1_grd.refined_inventory_dict[key], \n",
    "    timeseries=True, \n",
    "    timescan=True, \n",
    "    mosaic=False, \n",
    "    overwrite=False, \n",
    "    subset=s1_grd.aoi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7* - Create a time-series animation\n",
    "\n",
    "For interactive presentations it is nice to have animated \"movies\". The following command allows you to create animated time-series of oyur processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Time-series folder\n",
    "ts_folder = join(s1_grd.processing_dir, '95', 'Timeseries')\n",
    "\n",
    "# create the animation\n",
    "raster.create_timeseries_animation(\n",
    "    timeseries_folder=ts_folder, \n",
    "    product_list=['bs.VV', 'bs.VH'], \n",
    "    out_folder=s1_grd.processing_dir,\n",
    "    shrink_factor=5, \n",
    "    add_dates=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
